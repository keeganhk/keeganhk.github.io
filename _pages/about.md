---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


About Me
======
I obtained my Ph.D. degree in Computer Science at City University of Hong Kong, supervised by Prof. [Junhui Hou](https://sites.google.com/site/junhuihoushomepage/). I was also fortunate to work closely with Prof. [Ying He](https://personal.ntu.edu.sg/yhe/) from NTU and Prof. [Wenping Wang](https://www.cs.hku.hk/people/academic-staff/wenping) from TAMU. Previously, I worked as a research intern guided by Prof. [Runmin Cong](https://rmcong.github.io/). I received my B.Sc. degree in Electronic Information Science and Technology at Beijing Normal University.


News
======
* [2023.09] Two papers, **NeuroGF** for neural geodesics learning, **UPIDet** for cross-modal 3D object detection, got accepted by **NeurIPS-2023**.
* [2023.12] One paper, **Cross-PCC** for cross-modal image-assisted unsupervised 3D point cloud completion, got accepted by **TMM**.
* [2023.12] One paper, **PointVST** for self-supervised 3D point cloud backbone pre-training, got accepted by **TVCG**.
* [2024.06] One paper, **SPCV** for spatio-temporal structurization of dynamic 3D point cloud sequences, got accepted by **TPAMI**.
* [2024.09] One paper, **Flatten Anything Model (FAM)** for neural surface parameterization (UV unwrapping), got accepted by **NeurIPS-2024**.
* [2025.03] One paper, **Human as Points (HaP)** for single-image 3D human reconstruction, got accepted by **TPAMI**.
* [2025.10] One paper, **HuGDiffusion** for 3D Human Gaussian Diffusion, got accepted by **TVCG**.


Research
======
The latest trend in the artificial intelligence era continues to blur the boundaries of different research domains and data modalities. In general, I have broad interests in developing deep learning models to solve various geometry, vision, and graphics problems.

My research during Ph.D. mainly includes the following tasks and topics:
* Geometric (Mesh, Point Cloud, Implicit Field) Computing and Modeling; 
* Neural 3D Representation, Rendering, Reconstruction, and Generation;
* Multi-Modal (2D-3D, Visual-Geometric) Learning: Pre-training, Alignment, Fusion, Distillation.

I am particularly interested in ***Neuralized Geometry Processing***, i.e., (1) (at the data level) exploring neural representations for geometric data; (2) (at the model level) replacing conventional geometric computation/optimization algorithms with more powerful neural architectures.

My current research concentrates on ***3D Generative Models*** and ***AI for Games***.



Services
======

* Conference Reviewer: NeurIPS, ICLR, ICML, CVPR, ICCV, ECCV, ACM MM, IJCAI, CVM, VCIP, etc.

* Journal Reviewer: TIP, TVCG, TCSVT, TITS, TGRS, JSTARS, IEEE/CAA Journal of Automatica Sinica, Scientific Reports, Multimedia Systems, The Visual Computer, Journal of Electronic Imaging, Virtual Reality & Intelligent Hardware, etc.


Selected Publications
======



<table style="border: none;">
  <tbody>
  
  
    <tr>
      <td style="border: none;" width="25%">
        <img src="images/FlexPara.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2504.19210">
          <papertitle><font size="3">FlexPara: Flexible Neural Surface Parameterization</font></papertitle>
        </a>
        <br>
        <font size="3">Yuming Zhao, <strong>Qijian Zhang</strong>, Junhui Hou, Jiazhi Xia, Wenping Wang, Ying He</font>
        <br>
        <font size="3"><em>Pre-print</em></font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/SuperCarver.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="http://arxiv.org/abs/2503.09439">
          <papertitle><font size="3">SuperCarver: Texture-Consistent 3D Geometry Super-Resolution for High-Fidelity Surface Detail Generation</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>, Xiaozheng Jian, Xuan Zhang, Wenping Wang, Junhui Hou</font>
        <br>
        <font size="3"><em>Pre-print</em></font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


  </tbody>
</table>



<hr style="border: 1.0px solid grey;"/>



<table style="border: none;">
  <tbody>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/HuGDiffusion.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2501.15008">
          <papertitle><font size="3">HuGDiffusion: Generalizable Single-Image Human Rendering via 3D Gaussian Diffusion</font></papertitle>
        </a>
        <br>
        <font size="3">Yingzhi Tang, <strong>Qijian Zhang</strong>, Junhui Hou</font>
        <br>
        <font size="3"><em>TVCG 2025</em></font>
      </td>
    </tr>

  
    <tr>
      <td style="border: none;" width="25%">
        <img src="images/HaP.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2311.02892">
          <papertitle><font size="3">Human as Points: Explicit Point-based 3D Human Reconstruction from Single-view RGB Images</font></papertitle>
        </a>
        <br>
        <font size="3">Yingzhi Tang, <strong>Qijian Zhang</strong>, Junhui Hou, Yebin Liu</font>
        <br>
        <font size="3"><em>TPAMI</em> 2025</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>

    
    <tr>
      <td style="border: none;" width="25%">
        <img src="images/FAM.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2405.14633">
          <papertitle><font size="3">Flatten Anything: Unsupervised Neural Surface Parameterization</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>, Junhui Hou, Wenping Wang, Ying He</font>
        <br>
        <font size="3"><em>NeurIPS</em> 2024</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>
    
    
    <tr>
      <td style="border: none;" width="25%">
        <img src="images/SPCV.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2403.01129">
          <papertitle><font size="3">Dynamic 3D Point Cloud Sequences as 2D Videos</font></papertitle>
        </a>
        <br>
        <font size="3">Yiming Zeng, Junhui Hou, <strong>Qijian Zhang</strong>, Siyu Ren, Wenping Wang</font>
        <br>
        <font size="3"><em>TPAMI</em> 2024</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/PointVST.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2212.14197">
          <papertitle><font size="3">PointVST: Self-Supervised Pre-training for 3D Point Clouds via View-Specific Point-to-Image Translation</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>, Junhui Hou</font>
        <br>
        <font size="3"><em>TVCG</em> 2023</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>
    

    <tr>
      <td style="border: none;" width="25%">
        <img src="images/Cross-PCC.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2212.00564">
          <papertitle><font size="3">Leveraging Single-View Images for Unsupervised 3D Point Cloud Completion</font></papertitle>
        </a>
        <br>
        <font size="3">Lintai Wu, <strong>Qijian Zhang</strong>, Junhui Hou, Yong Xu</font>
        <br>
        <font size="3"><em>TMM</em> 2023</font>
      </td>
    </tr>

    
    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>

    
    <tr>
      <td style="border: none;" width="25%">
        <img src="images/NeuroGF.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2306.00658">
          <papertitle><font size="3">NeuroGF: A Neural Representation for Fast Geodesic Distance and Path Queries</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>, Junhui Hou, Yohanes Yudhi Adikusuma, Wenping Wang, Ying He</font>
        <br>
        <font size="3"><em>NeurIPS</em> 2023</font>
      </td>
    </tr>

    
    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/UPIDet.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2301.09077">
          <papertitle><font size="3">Unleash the Potential of Image Branch for Cross-modal 3D Object Detection</font></papertitle>
        </a>
        <br>
        <font size="3">Yifan Zhang, <strong>Qijian Zhang</strong>, Junhui Hou, Yixuan Yuan, Guoliang Xing</font>
        <br>
        <font size="3"><em>NeurIPS</em> 2023</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>

    
    <tr>
      <td style="border: none;" width="25%">
        <img src="images/PointMCD.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2207.03128">
          <papertitle><font size="3">PointMCD: Boosting Deep Point Cloud Encoders via Multi-view Cross-modal Distillation for 3D Shape Recognition</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>, Junhui Hou, Yue Qian</font>
        <br>
        <font size="3"><em>TMM</em> 2023</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/GLENet.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2207.02466">
          <papertitle><font size="3">GLENet: Boosting 3D Object Detectors with Generative Label Uncertainty Estimation</font></papertitle>
        </a>
        <br>
        <font size="3">Yifan Zhang, <strong>Qijian Zhang</strong>, Zhiyu Zhu, Junhui Hou, Yixuan Yuan</font>
        <br>
        <font size="3"><em>IJCV</em> 2023</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>

    
    <tr>
      <td style="border: none;" width="25%">
        <img src="images/MOPS-Net.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="files/MOPS-Net_TCSVT2023.pdf">
          <papertitle><font size="3">Task-Oriented Compact Representation of 3D Point Clouds via A Matrix Optimization-Driven Network</font></papertitle>
        </a>
        <br>
        <font size="3">Yue Qian, Junhui Hou, <strong>Qijian Zhang</strong>, Yiming Zeng, Sam Kwong, Ying He</font>
        <br>
        <font size="3"><em>TCSVT</em> 2023</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/Flattening-Net.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2212.08892">
          <papertitle><font size="3">Flattening-Net: Deep Regular 2D Representation for 3D Point Cloud Analysis</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>, Junhui Hou, Yue Qian, Yiming Zeng, Juyong Zhang, Ying He</font>
        <br>
        <font size="3"><em>TPAMI</em> 2023</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>
    

    <tr>
      <td style="border: none;" width="25%">
        <img src="images/RegGeoNet.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="files/RegGeoNet_IJCV2022.pdf">
          <papertitle><font size="3">RegGeoNet: Learning Regular Representations for Large-Scale 3D Point Clouds</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>, Junhui Hou, Yue Qian, Antoni B. Chan, Juyong Zhang, Ying He</font>
        <br>
        <font size="3"><em>IJCV</em> 2022</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/WarpingGAN.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2203.12917">
          <papertitle><font size="3">WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation</font></papertitle>
        </a>
        <br>
        <font size="3">Yingzhi Tang, Yue Qian, <strong>Qijian Zhang</strong>, Yiming Zeng, Junhui Hou, Xuefei Zhe</font>
        <br>
        <font size="3"><em>CVPR</em> 2022</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/IDEA-Net.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2203.11590">
          <papertitle><font size="3">IDEA-Net: Dynamic 3D Point Cloud Interpolation via Deep Embedding Alignment</font></papertitle>
        </a>
        <br>
        <font size="3">Yiming Zeng, Yue Qian, <strong>Qijian Zhang</strong>, Junhui Hou, Yixuan Yuan, Ying He</font>
        <br>
        <font size="3"><em>CVPR</em> 2022</font>
      </td>
    </tr>


    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/DAFNet.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2011.13144">
          <papertitle><font size="3">Dense Attention Fluid Network for Salient Object Detection in Optical Remote Sensing Images</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>, Runmin Cong, Chongyi Li, Ming-Ming Cheng, Yuming Fang, Xiaochun Cao, Yao Zhao, Sam Kwong</font>
        <br>
        <font size="3"><em>TIP</em> 2021</font>
      </td>
    </tr>
    

    <tr style="height: 15px; background: transparent; border: none;">
      <td colspan="2" style="border: none; padding: 0;"></td>
    </tr>


    <tr>
      <td style="border: none;" width="25%">
        <img src="images/CoADNet.png" height="100">
      </td>
      <td style="border: none;" width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2011.04887">
          <papertitle><font size="3">CoADNet: Collaborative Aggregation-and-Distribution Networks for Co-Salient Object Detection</font></papertitle>
        </a>
        <br>
        <font size="3"><strong>Qijian Zhang</strong>*, Runmin Cong* , Junhui Hou, Chongyi Li, Yao Zhao</font>
        <br>
        <font size="3"><em>NeurIPS</em> 2020</font>
      </td>
    </tr>


  </tbody>
</table>






<p></p>


